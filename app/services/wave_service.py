# app/services/wave_service.py
# -----------------------------------------------------------------------------
# Orchestrator for wave analysis pipeline.
# Load data -> compute scenarios (Dow + Elliott + Fibo + Indicators) -> payload.
# + Elliott RULES + FRACTAL bundle (data-driven) merged in.
# -----------------------------------------------------------------------------
from __future__ import annotations

from dataclasses import dataclass, asdict
from typing import Dict, Optional, Any, List
import pandas as pd
import math

from app.analysis.timeframes import get_data
# ðŸ”§ logic layer
from app.logic.scenarios import analyze_scenarios
from app.logic.elliott_logic import classify_elliott_with_kind
# ðŸ”Œ live data (ccxt/binance) â€” safe wrapper
from app.adapters.price_provider import get_ohlcv_ccxt_safe

# âœ… data-driven Elliott (rules + fractal)
from app.analysis.elliott_rules import analyze_elliott_rules_v2
from app.analysis.elliott_fractal import analyze_elliott_fractal

__all__ = ["analyze_wave", "build_brief_message", "analyze_df_elliott", "analyze_elliott_bundle", "WaveAnalyzeOptions"]


# -----------------------------------------------------------------------------
# Helpers (generic)
# -----------------------------------------------------------------------------
def _neutral_payload(symbol: str, tf: str, err: Optional[Exception] = None) -> Dict[str, Any]:
    note = f"Data not available: {err}" if err else "Data not available"
    return {
        "symbol": symbol,
        "tf": tf,
        "percent": {"up": 33, "down": 33, "side": 34},
        "levels": {},
        "rationale": [note],
        "meta": {"error": str(err) if err else None},
    }


def _merge_dict(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    """Recursive merge b over a."""
    out = dict(a)
    for k, v in (b or {}).items():
        if isinstance(v, dict) and isinstance(out.get(k), dict):
            out[k] = _merge_dict(out[k], v)
        else:
            out[k] = v
    return out


def _fmt_num(v: Optional[float]) -> Optional[str]:
    if isinstance(v, (int, float)) and not math.isnan(v):
        return f"{v:,.2f}"
    return None


def _to_pair(symbol: str) -> str:
    """
    à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸¹à¸›à¹à¸šà¸šà¸„à¸¹à¹ˆà¹€à¸—à¸£à¸”à¸ªà¸³à¸«à¸£à¸±à¸š live data:
    - à¸–à¹‰à¸² symbol à¸¡à¸µ "/" à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§ â†’ à¸„à¸·à¸™à¹€à¸”à¸´à¸¡
    - à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ BTCUSDT â†’ à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ BTC/USDT
    - à¸­à¸·à¹ˆà¸™ à¹† â†’ à¸œà¸¹à¸à¸à¸±à¸š USDT à¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ à¹€à¸Šà¹ˆà¸™ BTC â†’ BTC/USDT
    """
    s = (symbol or "").strip().upper()
    if "/" in s:
        return s
    if s.endswith("USDT") and len(s) > 4:
        return f"{s[:-4]}/USDT"
    return f"{s}/USDT"


# -----------------------------------------------------------------------------
# Elliott bundle (RULES + FRACTAL) â€” data-driven layer
# -----------------------------------------------------------------------------
@dataclass
class WaveAnalyzeOptions:
    schema_path: Optional[str] = None
    # rules layer
    pivot_left: Optional[int] = None
    pivot_right: Optional[int] = None
    max_swings: Optional[int] = None
    # fractal layer
    enable_fractal: bool = True
    degree: str = "Minute"
    sub_pivot_left: int = 2
    sub_pivot_right: int = 2


def analyze_elliott_bundle(df: pd.DataFrame, opts: Optional[WaveAnalyzeOptions] = None) -> Dict[str, Any]:
    """
    à¸£à¸§à¸¡à¸œà¸¥ RULES + (à¹€à¸¥à¸·à¸­à¸à¹„à¸”à¹‰) FRACTAL à¹€à¸›à¹‡à¸™à¹à¸žà¹‡à¸à¹€à¸”à¸µà¸¢à¸§à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¹ƒà¸™ LINE bot / engine
    à¹„à¸¡à¹ˆà¸—à¸³ IO à¹ƒà¸” à¹† â€” à¸£à¸±à¸š df à¸žà¸£à¹‰à¸­à¸¡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ high/low/close à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
    """
    opts = opts or WaveAnalyzeOptions()

    # 1) RULES
    rules_res = analyze_elliott_rules_v2(
        df,
        schema_path=opts.schema_path,
        pivot_left=opts.pivot_left,
        pivot_right=opts.pivot_right,
        max_swings=opts.max_swings,
    )

    # 2) FRACTAL (à¸•à¹ˆà¸­à¸¢à¸­à¸”à¸ˆà¸²à¸à¸«à¸™à¹‰à¸²à¸•à¹ˆà¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™)
    if opts.enable_fractal:
        fractal_res = analyze_elliott_fractal(
            df,
            schema_path=opts.schema_path,
            degree=opts.degree,
            sub_pivot_left=opts.sub_pivot_left,
            sub_pivot_right=opts.sub_pivot_right,
        )
    else:
        fractal_res = {**rules_res, "fractal": {"checked": False, "reason": "disabled"}}

    # 3) à¸£à¸§à¸¡à¸œà¸¥: à¹€à¸¥à¸·à¸­à¸à¸Ÿà¸´à¸¥à¸”à¹Œà¸ªà¸³à¸„à¸±à¸ + à¹à¸™à¸šà¸”à¸µà¸šà¸±à¹Šà¸
    bundle: Dict[str, Any] = {
        "pattern": fractal_res.get("pattern", rules_res.get("pattern", "UNKNOWN")),
        "variant": fractal_res.get("variant", rules_res.get("variant", "")),
        "wave_label": fractal_res.get("wave_label", rules_res.get("wave_label", "UNKNOWN")),
        "rules": rules_res.get("rules", []),
        "fractal": fractal_res.get("fractal", {"checked": False}),
        "degree": fractal_res.get("degree", opts.degree),
        "targets": rules_res.get("targets", {}),  # RULES layer à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸•à¸±à¹‰à¸‡à¹€à¸›à¹‰à¸² â†’ à¹€à¸§à¹‰à¸™à¸§à¹ˆà¸²à¸‡à¹„à¸§à¹‰
        "completed": bool(rules_res.get("completed", False) and fractal_res.get("fractal", {}).get("passed_all_subwaves", False)),
        "debug": {
            "rules_debug": rules_res.get("debug", {}),
            "fractal_debug": fractal_res.get("debug", {}),
        },
        "meta": {
            "options": asdict(opts),
            "schema_used": opts.schema_path or "default",
        },
    }
    return bundle


def analyze_df_elliott(df: pd.DataFrame, **kwargs) -> Dict[str, Any]:
    """
    proxy à¹à¸šà¸š keyword-friendly:
    analyze_df_elliott(df, enable_fractal=True, degree="Minute",
                       sub_pivot_left=2, sub_pivot_right=2, ...)
    """
    opts = WaveAnalyzeOptions(**kwargs)
    return analyze_elliott_bundle(df, opts)


# -----------------------------------------------------------------------------
# Public API (orchestrator)
# -----------------------------------------------------------------------------
def analyze_wave(
    symbol: str,
    tf: str = "1D",
    *,
    xlsx_path: Optional[str] = "app/data/historical.xlsx",
    cfg: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """
    End-to-end analysis:
      - à¸«à¸²à¸ cfg['use_live'] à¹€à¸›à¹‡à¸™ True: à¹‚à¸«à¸¥à¸” OHLCV à¸ˆà¸²à¸ Binance (à¸œà¹ˆà¸²à¸™ price_provider)
      - à¹„à¸¡à¹ˆà¹€à¸Šà¹ˆà¸™à¸™à¸±à¹‰à¸™: à¹‚à¸«à¸¥à¸”à¸ˆà¸²à¸ Excel/CSV (à¸œà¹ˆà¸²à¸™ timeframes.get_data)
      - Run scenarios (+ optional Weekly context)
      - à¹à¸™à¸š Elliott (RULES + FRACTAL bundle)
      - à¹à¸™à¸š TP/SL (3%,5%,7% / SL 3%) à¹à¸¥à¸° metadata à¸žà¸·à¹‰à¸™à¸à¸²à¸™
    """
    cfg = cfg or {}

    # 1) Load main TF data (live à¸«à¸£à¸·à¸­ file)
    try:
        if cfg.get("use_live"):
            limit = int(cfg.get("live_limit", 500))
            pair = _to_pair(symbol)
            df: pd.DataFrame = get_ohlcv_ccxt_safe(pair, tf, limit)
            if df is None or df.empty:
                return _neutral_payload(symbol, tf, err=RuntimeError("no live OHLCV"))
        else:
            df: pd.DataFrame = get_data(symbol, tf, xlsx_path=xlsx_path)
            if df is None or df.empty:
                return _neutral_payload(symbol, tf)
    except Exception as e:
        return _neutral_payload(symbol, tf, e)

    # 2) Merge config (safe defaults)
    base_cfg: Dict[str, Any] = {"elliott": {"allow_diagonal": True}}
    merged_cfg: Dict[str, Any] = _merge_dict(base_cfg, cfg or {})

    # 3) Weekly context (1W) â€” best effort (à¹ƒà¸Šà¹‰ logic à¹€à¸”à¸´à¸¡ à¹€à¸žà¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¸à¸±à¸™à¹„à¸”à¹‰à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡)
    weekly_ctx: Optional[Dict[str, Any]] = None
    try:
        if cfg.get("use_live"):
            wdf = get_ohlcv_ccxt_safe(_to_pair(symbol), "1W", int(cfg.get("live_limit", 500)))
        else:
            wdf = get_data(symbol, "1W", xlsx_path=xlsx_path)
        if wdf is not None and not wdf.empty:
            weekly_ctx = classify_elliott_with_kind(wdf, timeframe="1W")
    except Exception:
        weekly_ctx = None  # fail-safe

    # 4) Run scenarios (à¸£à¸­à¸‡à¸£à¸±à¸š weekly_ctx à¸–à¹‰à¸²à¸¡à¸µ)
    try:
        payload = analyze_scenarios(df, symbol=symbol, tf=tf, cfg=merged_cfg, weekly_ctx=weekly_ctx)
    except TypeError:
        payload = analyze_scenarios(df, symbol=symbol, tf=tf, cfg=merged_cfg)

    # 4.1) à¹à¸™à¸š Elliott (RULES + FRACTAL bundle) à¸¥à¸‡ levels.elliott à¹€à¸žà¸·à¹ˆà¸­ surface à¹ƒà¸™ LINE/à¸£à¸²à¸¢à¸‡à¸²à¸™
    try:
        ell_opts = (merged_cfg.get("elliott_opts") or {})  # à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¹ˆà¸‡ override à¹„à¸”à¹‰à¹ƒà¸™ cfg
        ell_res = analyze_df_elliott(
            df,
            **{
                "schema_path": ell_opts.get("schema_path"),
                "pivot_left": ell_opts.get("pivot_left"),
                "pivot_right": ell_opts.get("pivot_right"),
                "max_swings": ell_opts.get("max_swings"),
                "enable_fractal": ell_opts.get("enable_fractal", True),
                "degree": ell_opts.get("degree", "Minute"),
                "sub_pivot_left": ell_opts.get("sub_pivot_left", 2),
                "sub_pivot_right": ell_opts.get("sub_pivot_right", 2),
            },
        )
        levels = payload.setdefault("levels", {})
        levels["elliott"] = {
            "pattern": ell_res.get("pattern", "UNKNOWN"),
            "variant": ell_res.get("variant", ""),
            "wave_label": ell_res.get("wave_label", "UNKNOWN"),
            "rules": ell_res.get("rules", []),
            "fractal": ell_res.get("fractal", {}),
            "degree": ell_res.get("degree"),
            "completed": ell_res.get("completed", False),
            "debug": ell_res.get("debug", {}),
        }
    except Exception as _e:
        # à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰ pipeline à¸¥à¹‰à¸¡ â€” à¹à¸„à¹ˆà¹à¸™à¸šà¹€à¸«à¸•à¸¸à¹„à¸§à¹‰à¹ƒà¸™ rationale
        payload.setdefault("rationale", []).append(f"Elliott (bundle) failed: {_e!s}")

    # 5) Attach last price/time (surface à¸ªà¸³à¸«à¸£à¸±à¸š LINE text)
    last = df.iloc[-1]
    px = float(last.get("close", float("nan")))
    payload["last"] = {
        "timestamp": str(last.get("timestamp", "")),
        "close": px,
        "high": float(last.get("high", float("nan"))),
        "low": float(last.get("low", float("nan"))),
        "volume": float(last.get("volume", float("nan"))),
    }

    # 6) Attach TP/SL rule (surface)
    tp_levels = [0.03, 0.05, 0.07]
    sl_level = 0.03
    if isinstance(px, (int, float)) and not math.isnan(px):
        payload["risk"] = {
            "entry": px,
            "tp": [px * (1 + t) for t in tp_levels],
            "sl": px * (1 - sl_level),
            "tp_pct": tp_levels,
            "sl_pct": sl_level,
        }

    # 7) Ensure meta fields
    payload["symbol"] = symbol
    payload["tf"] = tf

    # 8) Surface weekly bias (à¸–à¹‰à¸²à¸¡à¸µ)
    try:
        if weekly_ctx:
            lv = payload.setdefault("levels", {})
            ell = lv.setdefault("elliott", {})
            cur = ell.setdefault("current", {})
            if "weekly_bias" not in cur and isinstance(weekly_ctx, dict):
                wb = (weekly_ctx.get("current") or {}).get("weekly_bias")
                if wb:
                    cur["weekly_bias"] = wb
    except Exception:
        pass

    return payload


def build_brief_message(payload: Dict[str, Any]) -> str:
    """
    Create a short summary suitable for LINE messages.
    Also prints trading plans (A/B/C) at the end for terminal usage.
    Safe even if fields are missing.
    """
    sym = payload.get("symbol", "")
    tf = payload.get("tf", "")
    pct = payload.get("percent", {}) or {}
    up, down, side = pct.get("up", "?"), pct.get("down", "?"), pct.get("side", "?")

    levels = payload.get("levels", {}) or {}
    rh, rl = levels.get("recent_high"), levels.get("recent_low")
    ema50, ema200 = levels.get("ema50"), levels.get("ema200")

    last = payload.get("last", {}) or {}
    px = last.get("close")

    risk = payload.get("risk", {}) or {}
    tp_pct: List[float] = risk.get("tp_pct", [0.03, 0.05, 0.07])
    sl_pct: float = risk.get("sl_pct", 0.03)

    # Optional weekly bias line
    weekly_line = ""
    wb_for_plan = "?"
    try:
        ell = levels.get("elliott") or {}
        cur = ell.get("current") or {}
        wb = cur.get("weekly_bias")
        if isinstance(wb, str) and wb:
            weekly_line = f" [{wb.upper()} 1W]"
            wb_for_plan = wb.upper()
    except Exception:
        pass

    lines: List[str] = []
    header = f"{sym} ({tf}){weekly_line}"
    lines.append(header)

    px_txt = _fmt_num(px)
    if px_txt:
        lines.append(f"à¸£à¸²à¸„à¸²: {px_txt}")

    lines.append(f"à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ â€” à¸‚à¸¶à¹‰à¸™ {up}% | à¸¥à¸‡ {down}% | à¸­à¸­à¸à¸‚à¹‰à¸²à¸‡ {side}%")

    rh_txt, rl_txt = _fmt_num(rh), _fmt_num(rl)
    if rh_txt and rl_txt:
        lines.append(f"à¸à¸£à¸­à¸šà¸¥à¹ˆà¸²à¸ªà¸¸à¸”: H {rh_txt} / L {rl_txt}")

    ema50_txt, ema200_txt = _fmt_num(ema50), _fmt_num(ema200)
    if ema50_txt and ema200_txt:
        lines.append(f"EMA50 {ema50_txt} / EMA200 {ema200_txt}")

    tp_txt = " / ".join([f"{int(t * 100)}%" for t in tp_pct])
    lines.append(f"TP: {tp_txt} | SL: {int(sl_pct * 100)}%")

    rationale = payload.get("rationale", []) or []
    if rationale:
        lines.append("à¹€à¸«à¸•à¸¸à¸œà¸¥à¸¢à¹ˆà¸­:")
        for r in rationale[:3]:
            lines.append(f"â€¢ {r}")

    # === Trading Plans block (terminal-friendly) ===
    try:
        px_val = float(px) if isinstance(px, (int, float)) else float("nan")
        rh_val = float(rh) if isinstance(rh, (int, float)) else None
        rl_val = float(rl) if isinstance(rl, (int, float)) else None
        ema50_val = float(ema50) if isinstance(ema50, (int, float)) else None

        lines.append("")
        lines.append(f"à¹à¸œà¸™à¹€à¸—à¸£à¸”à¸—à¸µà¹ˆà¹à¸™à¸°à¸™à¸³à¸•à¸­à¸™à¸™à¸µà¹‰ (Weekly = {wb_for_plan}, 1D bias à¸‚à¸¶à¹‰à¸™/à¸¥à¸‡/à¸‚à¹‰à¸²à¸‡ = {up}%/{down}%/{side}%)")

        # A) Short â€“ Breakout
        if rl_val and rl_val > 0:
            entry = rl_val
            lines.append("")
            lines.append("A) Short â€“ Breakout (à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸à¸§à¹ˆà¸²)")
            lines.append(f"Entry: à¸«à¸¥à¸¸à¸” {entry:,.2f}")
            tp1, tp2, tp3 = entry * 0.97, entry * 0.95, entry * 0.93
            sl = entry * 1.03
            lines.append(f"TP1 âˆ’3%: {tp1:,.2f} | TP2 âˆ’5%: {tp2:,.2f} | TP3 âˆ’7%: {tp3:,.2f}")
            lines.append(f"SL +3%: {sl:,.2f}")

        # B) Short â€“ Pullback
        if ema50_val and ema50_val > 0:
            entry = ema50_val
            lines.append("")
            lines.append("B) Short â€“ Pullback (à¹€à¸Šà¸´à¸‡à¸£à¸¸à¸/RR à¸”à¸µà¸à¸§à¹ˆà¸²)")
            lines.append(f"Entry: à¸£à¸µà¹€à¸ˆà¹‡à¸à¸•à¹Œà¹à¸–à¸§ EMA50 = {entry:,.2f}")
            tp1, tp2, tp3 = entry * 0.97, entry * 0.95, entry * 0.93
            sl = entry * 1.03
            lines.append(f"TP1 âˆ’3%: {tp1:,.2f} | TP2 âˆ’5%: {tp2:,.2f} | TP3 âˆ’7%: {tp3:,.2f}")
            lines.append(f"SL +3%: {sl:,.2f}")

        # C) Long â€“ à¹à¸œà¸™à¸ªà¸³à¸£à¸­à¸‡
        if rh_val and rh_val > 0:
            entry = rh_val
            lines.append("")
            lines.append("C) Long â€“ à¹à¸œà¸™à¸ªà¸³à¸£à¸­à¸‡ (à¸–à¹‰à¸²à¸à¸¥à¸±à¸šà¸•à¸±à¸§à¹à¸£à¸‡)")
            lines.append(f"Entry: à¸—à¸°à¸¥à¸¸ Recent High = {entry:,.2f}")
            tp1, tp2, tp3 = entry * 1.03, entry * 1.05, entry * 1.07
            sl = entry * 0.97
            lines.append(f"TP1 +3%: {tp1:,.2f} | TP2 +5%: {tp2:,.2f} | TP3 +7%: {tp3:,.2f}")
            lines.append(f"SL âˆ’3%: {sl:,.2f}")
    except Exception:
        pass

    return "\n".join(lines)

# [à¹„à¸Ÿà¸¥à¹Œ] app/services/wave_service.py (à¹€à¸žà¸´à¹ˆà¸¡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹ƒà¸«à¸¡à¹ˆà¸—à¹‰à¸²à¸¢à¹„à¸Ÿà¸¥à¹Œ)

import json

# [à¹„à¸Ÿà¸¥à¹Œ] app/services/wave_service.py  (à¹€à¸žà¸´à¹ˆà¸¡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™/à¸­à¸±à¸›à¹€à¸”à¸•à¹ƒà¸«à¹‰à¸£à¸§à¸¡ 1D)
# à¸§à¸²à¸‡à¸•à¹ˆà¸­à¸—à¹‰à¸²à¸¢à¹„à¸Ÿà¸¥à¹Œ (à¸«à¸£à¸·à¸­à¹à¸—à¸™à¸—à¸µà¹ˆà¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ build_brief_message à¹€à¸”à¸´à¸¡)

def build_brief_message(result: dict) -> str:
    """à¹à¸›à¸¥à¸‡ scenario JSON -> à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ªà¸±à¹‰à¸™à¸ªà¹ˆà¸‡ LINE (à¸£à¸§à¸¡ 1H/4H/1D)"""
    sym = result.get("symbol", "?")
    sc = result.get("scenario", {})
    last1 = result.get("last_1H", {})
    last4 = result.get("last_4H", {})
    lastD = result.get("last_1D", {})
    reasons = sc.get("reasons", [])

    def pct(x): return f"{x:.1f}%" if isinstance(x, (int, float)) else "?"
    def fmt_num(x, nd=2): 
        try: return f"{float(x):.{nd}f}"
        except: return "?"

    msg = (
        f"[{sym}] Scenario\n"
        f"UP {pct(sc.get('UP_pct'))} | DOWN {pct(sc.get('DOWN_pct'))} | SIDE {pct(sc.get('SIDE_pct'))}\n"
        f"1H Close {fmt_num(last1.get('close'))} | RSI {fmt_num(last1.get('rsi14'),1)}\n"
        f"4H Close {fmt_num(last4.get('close'))} | RSI {fmt_num(last4.get('rsi14'),1)}\n"
        f"1D Close {fmt_num(lastD.get('close'))} | RSI {fmt_num(lastD.get('rsi14'),1)}\n"
    )
    if reasons:
        msg += "Reasons: " + "; ".join(reasons[:4])
    return msg
